{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuX1BgzzoDwFrXxitwEbwR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asifsiraz/Beginner-ML-project/blob/main/Mnist_batch_relu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the model with batch normalization and ReLU activation\n",
        "def create_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Flatten(input_shape=(28, 28)),\n",
        "        layers.Dense(256, activation='relu', kernel_initializer='he_normal'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = create_model()\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Function to calculate the percentage of active nodes in each layer using forward pass\n",
        "def calculate_active_nodes_percentage(model, x):\n",
        "    active_nodes_percentages = []\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, layers.Dense):\n",
        "            # Perform forward pass\n",
        "            x = layer(x)\n",
        "            # Identify active nodes (non-zero activations) for the current layer\n",
        "            active_nodes = np.sum(x.numpy() != 0)\n",
        "            total_nodes = np.prod(x.shape[-1])\n",
        "            active_nodes_percentage = (active_nodes / total_nodes) * 100\n",
        "            active_nodes_percentages.append(active_nodes_percentage)\n",
        "    return active_nodes_percentages\n",
        "\n",
        "# Create a sample batch for the forward pass\n",
        "# Flatten the input data before passing it to the model\n",
        "sample_batch_flattened = sample_batch.reshape(sample_batch.shape[0], -1)\n",
        "\n",
        "# Calculate the percentage of active nodes for each layer using forward pass\n",
        "active_nodes_percentages = calculate_active_nodes_percentage(model, sample_batch_flattened)\n",
        "for i, percentage in enumerate(active_nodes_percentages, start=1):\n",
        "    print(f\"Layer {i}: {percentage:.2f}% active nodes\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(\"Test accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qSQjmwuBcJRw",
        "outputId": "93f2efc8-7fc8-480d-98ed-76b9b3ee392a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2614 - accuracy: 0.9215 - val_loss: 0.1167 - val_accuracy: 0.9629\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.1270 - accuracy: 0.9609 - val_loss: 0.0970 - val_accuracy: 0.9703\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0956 - accuracy: 0.9704 - val_loss: 0.1005 - val_accuracy: 0.9701\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0788 - accuracy: 0.9747 - val_loss: 0.0851 - val_accuracy: 0.9752\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0678 - accuracy: 0.9786 - val_loss: 0.0914 - val_accuracy: 0.9732\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0599 - accuracy: 0.9806 - val_loss: 0.0850 - val_accuracy: 0.9766\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0520 - accuracy: 0.9826 - val_loss: 0.0835 - val_accuracy: 0.9761\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9847 - val_loss: 0.0853 - val_accuracy: 0.9772\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0433 - accuracy: 0.9850 - val_loss: 0.0860 - val_accuracy: 0.9760\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0372 - accuracy: 0.9875 - val_loss: 0.0944 - val_accuracy: 0.9750\n",
            "Layer 1: 1080.86% active nodes\n",
            "Layer 2: 1234.38% active nodes\n",
            "Layer 3: 1281.25% active nodes\n",
            "Layer 4: 3200.00% active nodes\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0815 - accuracy: 0.9771\n",
            "Test accuracy: 0.9771000146865845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils\n",
        "from tensorflow.keras.regularizers import l1  # Import the L1 regularization\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the model with batch normalization and ReLU activation, and L1 regularization\n",
        "def create_model_with_l1():\n",
        "    model = models.Sequential([\n",
        "        layers.Flatten(input_shape=(28, 28)),\n",
        "        layers.Dense(256, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l1(0.01)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(128, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l1(0.01)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(64, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l1(0.01)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Train the model with L1 regularization\n",
        "model_with_l1 = create_model_with_l1()\n",
        "model_with_l1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_with_l1.fit(train_images, train_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Function to calculate the percentage of active nodes in each layer using forward pass\n",
        "def calculate_active_nodes_percentage(model, x):\n",
        "    active_nodes_percentages = []\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, layers.Dense):\n",
        "            # Perform forward pass\n",
        "            x = layer(x)\n",
        "            # Identify active nodes (non-zero activations) for the current layer\n",
        "            active_nodes = np.sum(x.numpy() != 0)\n",
        "            total_nodes = np.prod(x.shape[-1])\n",
        "            active_nodes_percentage = (active_nodes / total_nodes) * 100\n",
        "            active_nodes_percentages.append(active_nodes_percentage)\n",
        "    return active_nodes_percentages\n",
        "\n",
        "# Create a sample batch for the forward pass\n",
        "sample_batch_flattened = train_images[:32].reshape(32, -1)\n",
        "\n",
        "# Calculate the percentage of active nodes for each layer using forward pass\n",
        "active_nodes_percentages = calculate_active_nodes_percentage(model_with_l1, sample_batch_flattened)\n",
        "for i, percentage in enumerate(active_nodes_percentages, start=1):\n",
        "    print(f\"Layer {i}: {percentage:.2f}% active nodes\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model_with_l1.evaluate(test_images, test_labels)\n",
        "print(\"Test accuracy:\", test_accuracy)\n",
        "\n",
        "def calculate_sparsity(model):\n",
        "    total_params = 0\n",
        "    zero_params = 0\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, layers.Dense):\n",
        "            # Get the layer's weights\n",
        "            weights = layer.get_weights()[0]\n",
        "            total_params += np.prod(weights.shape)\n",
        "            zero_params += np.sum(np.abs(weights) < 1e-5)  # Count the number of near-zero weights\n",
        "    sparsity = zero_params / total_params * 100\n",
        "    return sparsity\n",
        "\n",
        "# Calculate the sparsity of the model\n",
        "sparsity = calculate_sparsity(model_with_l1)\n",
        "print(f\"Model Sparsity: {sparsity:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gIRza3zvgVB8",
        "outputId": "1d913751-07f6-4a0a-c4c6-cf311466b17b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 14s 8ms/step - loss: 7.4583 - accuracy: 0.8338 - val_loss: 1.6411 - val_accuracy: 0.8356\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 1.3477 - accuracy: 0.8818 - val_loss: 1.3031 - val_accuracy: 0.8713\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 1.1979 - accuracy: 0.8905 - val_loss: 2.1923 - val_accuracy: 0.6378\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 1.1348 - accuracy: 0.8966 - val_loss: 1.2306 - val_accuracy: 0.8720\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 1.1138 - accuracy: 0.8968 - val_loss: 1.1136 - val_accuracy: 0.8847\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 1.0843 - accuracy: 0.8989 - val_loss: 1.0817 - val_accuracy: 0.8951\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 1.0660 - accuracy: 0.8978 - val_loss: 1.1126 - val_accuracy: 0.8892\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 1.0569 - accuracy: 0.8982 - val_loss: 1.1900 - val_accuracy: 0.8683\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 1.0537 - accuracy: 0.9003 - val_loss: 1.0173 - val_accuracy: 0.9085\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 1.0569 - accuracy: 0.8997 - val_loss: 1.0150 - val_accuracy: 0.9040\n",
            "Layer 1: 157.42% active nodes\n",
            "Layer 2: 280.47% active nodes\n",
            "Layer 3: 1800.00% active nodes\n",
            "Layer 4: 3200.00% active nodes\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.9050\n",
            "Test accuracy: 0.9049999713897705\n",
            "Model Sparsity: 6.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils\n",
        "from tensorflow.keras.regularizers import l1  # Import the L1 regularization\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the model with batch normalization and ReLU activation, and L1 regularization\n",
        "def create_model_with_l1():\n",
        "    model = models.Sequential([\n",
        "        layers.Flatten(input_shape=(28, 28)),\n",
        "        layers.Dense(256, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l1(0.001)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(128, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l1(0.001)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(64, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l1(0.001)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Train the model with L1 regularization\n",
        "model_with_l1 = create_model_with_l1()\n",
        "model_with_l1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_with_l1.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Function to calculate the percentage of active nodes in each layer using forward pass\n",
        "def calculate_active_nodes_percentage(model, x):\n",
        "    active_nodes_percentages = []\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, layers.Dense):\n",
        "            # Perform forward pass\n",
        "            x = layer(x)\n",
        "            # Identify active nodes (non-zero activations) for the current layer\n",
        "            active_nodes = np.sum(x.numpy() != 0)\n",
        "            total_nodes = np.prod(x.shape[-1])\n",
        "            active_nodes_percentage = (active_nodes / total_nodes) * 100\n",
        "            active_nodes_percentages.append(active_nodes_percentage)\n",
        "    return active_nodes_percentages\n",
        "\n",
        "# Create a sample batch for the forward pass\n",
        "sample_batch_flattened = train_images[:64].reshape(64, -1)\n",
        "\n",
        "# Calculate the percentage of active nodes for each layer using forward pass\n",
        "active_nodes_percentages = calculate_active_nodes_percentage(model_with_l1, sample_batch_flattened)\n",
        "for i, percentage in enumerate(active_nodes_percentages, start=1):\n",
        "    print(f\"Layer {i}: {percentage:.2f}% active nodes\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model_with_l1.evaluate(test_images, test_labels)\n",
        "print(\"Test accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0ujbRXbOlYnK",
        "outputId": "b2949ea2-4250-4122-8cea-392029d51a55"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 10s 11ms/step - loss: 3.7749 - accuracy: 0.9093 - val_loss: 1.5384 - val_accuracy: 0.9222\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 1.1372 - accuracy: 0.9292 - val_loss: 0.9673 - val_accuracy: 0.9106\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 9s 11ms/step - loss: 0.7468 - accuracy: 0.9398 - val_loss: 0.6338 - val_accuracy: 0.9467\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.5899 - accuracy: 0.9468 - val_loss: 0.6392 - val_accuracy: 0.9214\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.5160 - accuracy: 0.9505 - val_loss: 0.5632 - val_accuracy: 0.9345\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.4855 - accuracy: 0.9514 - val_loss: 0.4800 - val_accuracy: 0.9493\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.4561 - accuracy: 0.9541 - val_loss: 0.5690 - val_accuracy: 0.9212\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.4405 - accuracy: 0.9547 - val_loss: 0.4585 - val_accuracy: 0.9463\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.4190 - accuracy: 0.9565 - val_loss: 0.4490 - val_accuracy: 0.9535\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.4201 - accuracy: 0.9561 - val_loss: 0.4500 - val_accuracy: 0.9513\n",
            "Layer 1: 560.94% active nodes\n",
            "Layer 2: 1181.25% active nodes\n",
            "Layer 3: 4346.88% active nodes\n",
            "Layer 4: 6400.00% active nodes\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.9503\n",
            "Test accuracy: 0.9502999782562256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_sparsity(model):\n",
        "    total_params = 0\n",
        "    zero_params = 0\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, layers.Dense):\n",
        "            # Get the layer's weights\n",
        "            weights = layer.get_weights()[0]\n",
        "            total_params += np.prod(weights.shape)\n",
        "            zero_params += np.sum(np.abs(weights) < 1e-5)  # Count the number of near-zero weights\n",
        "    sparsity = zero_params / total_params * 100\n",
        "    return sparsity\n",
        "\n",
        "# Calculate the sparsity of the model\n",
        "sparsity = calculate_sparsity(model_with_l1)\n",
        "print(f\"Model Sparsity: {sparsity:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xJLek4QrmU7y",
        "outputId": "69a16630-86f9-4af6-83f3-553c27fa5134"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Sparsity: 6.37%\n"
          ]
        }
      ]
    }
  ]
}